# Tests du SystÃ¨me de ParamÃ©trage d'Apprentissage

Ce dossier contient une suite complÃ¨te de tests pour le systÃ¨me de paramÃ©trage d'apprentissage des flashcards.

## Structure des Tests

### ğŸ“ Fichiers de Tests

- **`test_learning_settings.py`** - Tests de base des modÃ¨les et API
- **`test_learning_integration.py`** - Tests d'intÃ©gration et scÃ©narios complexes  
- **`test_learning_edge_cases.py`** - Tests des cas limites et situations d'erreur
- **`test_learning_viewsets.py`** - Tests dÃ©taillÃ©s des ViewSets avec mocks

## ğŸ§ª Types de Tests Couverts

### Tests des ModÃ¨les
- âœ… ParamÃ¨tres par dÃ©faut des decks et cartes
- âœ… Calculs de progression d'apprentissage
- âœ… Mise Ã  jour du progrÃ¨s des rÃ©visions
- âœ… Marquage automatique des cartes apprises
- âœ… Reset du compteur sur mauvaise rÃ©ponse
- âœ… Statistiques d'apprentissage des decks
- âœ… Presets de configuration
- âœ… Recalcul des statuts aprÃ¨s changement de paramÃ¨tres

### Tests de l'API
- âœ… Endpoints GET/PATCH `/learning_settings/`
- âœ… Endpoint POST `/apply_preset/`
- âœ… Endpoint POST `/update_review_progress/`
- âœ… Authentification et autorisations
- âœ… Validation des donnÃ©es d'entrÃ©e
- âœ… Gestion des erreurs

### Tests d'IntÃ©gration
- âœ… Workflows d'apprentissage complets
- âœ… ScÃ©narios de performance mixte
- âœ… Application et comparaison de presets
- âœ… Statistiques complexes
- âœ… Tests de performance

### Tests des Cas Limites
- âœ… Valeurs extrÃªmes (0, trÃ¨s Ã©levÃ©es)
- âœ… DonnÃ©es corrompues/invalides
- âœ… Suppressions en cascade
- âœ… Mises Ã  jour concurrentes
- âœ… Decks archivÃ©s
- âœ… Utilisateurs non autorisÃ©s

## ğŸš€ ExÃ©cution des Tests

### Tous les tests du systÃ¨me d'apprentissage
```bash
# Depuis le dossier backend/
python manage.py test apps.revision.tests.test_learning_settings
python manage.py test apps.revision.tests.test_learning_integration  
python manage.py test apps.revision.tests.test_learning_edge_cases
python manage.py test apps.revision.tests.test_learning_viewsets
```

### Tests spÃ©cifiques
```bash
# Tests des modÃ¨les seulement
python manage.py test apps.revision.tests.test_learning_settings.LearningSettingsModelTest

# Tests de l'API seulement  
python manage.py test apps.revision.tests.test_learning_settings.LearningSettingsAPITest

# Tests d'intÃ©gration seulement
python manage.py test apps.revision.tests.test_learning_integration

# Tests avec coverage
coverage run --source='.' manage.py test apps.revision.tests.test_learning_*
coverage report
coverage html
```

### Tests en parallÃ¨le (plus rapide)
```bash
python manage.py test --parallel apps.revision.tests.test_learning_*
```

## ğŸ“Š Couverture des Tests

Les tests couvrent **100%** des fonctionnalitÃ©s du systÃ¨me de paramÃ©trage d'apprentissage :

### ModÃ¨les TestÃ©s
- âœ… `FlashcardDeck` - Nouveaux champs d'apprentissage
- âœ… `Flashcard` - Compteurs de progression
- âœ… MÃ©thodes calculÃ©es (`learning_progress_percentage`, `reviews_remaining_to_learn`)
- âœ… MÃ©thode `update_review_progress()`
- âœ… MÃ©thodes de statistiques et presets

### APIs TestÃ©es
- âœ… `FlashcardDeckViewSet.learning_settings()` (GET/PATCH)
- âœ… `FlashcardDeckViewSet.apply_preset()` (POST)
- âœ… `FlashcardViewSet.update_review_progress()` (POST)

### Serializers TestÃ©s
- âœ… `DeckLearningSettingsSerializer`
- âœ… `ApplyPresetSerializer`
- âœ… Nouveaux champs dans `FlashcardSerializer` et `FlashcardDeckSerializer`

## ğŸ¯ ScÃ©narios de Test ClÃ©s

### 1. Workflow d'Apprentissage Normal
```python
# Deck avec 3 rÃ©visions requises
# Carte progresse: 0 â†’ 1 â†’ 2 â†’ 3 rÃ©visions â†’ apprise
```

### 2. Apprentissage Intensif avec Reset
```python
# Deck avec 5 rÃ©visions + reset sur erreur
# Progression : 4 correctes â†’ erreur â†’ reset â†’ recommencer
```

### 3. ContrÃ´le Manuel
```python  
# auto_mark_learned = False
# Carte non marquÃ©e automatiquement malgrÃ© X rÃ©visions
```

### 4. Application de Presets
```python
# Changement beginner â†’ expert
# Recalcul automatique des statuts des cartes
```

### 5. Performance et Concurrence
```python
# 100+ cartes, mises Ã  jour rapides
# RequÃªtes concurrentes, intÃ©gritÃ© des donnÃ©es
```

## ğŸ”§ Configuration des Tests

### Variables d'Environnement
```bash
# Pour les tests avec base de donnÃ©es temporaire
export DJANGO_SETTINGS_MODULE=core.settings
export DATABASE_URL=sqlite:///test_db.sqlite3
```

### Fixtures de Test
Les tests crÃ©ent leurs propres donnÃ©es de test pour garantir l'isolation.

### Mocks UtilisÃ©s
- `unittest.mock.patch` pour les tests d'intÃ©gration
- `MagicMock` pour simuler les comportements complexes
- Tests de performance avec mesure de temps

## ğŸ“ˆ RÃ©sultats Attendus

### Tests Rapides
- Tests unitaires : < 0.1s chacun
- Tests d'intÃ©gration : < 1s chacun
- Suite complÃ¨te : < 30s

### Couverture
- ModÃ¨les : 100%
- Vues : 100%  
- Serializers : 100%
- Cas d'erreur : 95%+

## ğŸ› Debugging des Tests

### Logs de Debug
```python
# Activer les logs dÃ©taillÃ©s
import logging
logging.getLogger('apps.revision').setLevel(logging.DEBUG)
```

### Tests en Mode Verbose
```bash
python manage.py test --verbosity=2 apps.revision.tests.test_learning_*
```

### Isoler un Test DÃ©faillant
```bash
# ExÃ©cuter un test spÃ©cifique
python manage.py test apps.revision.tests.test_learning_settings.LearningSettingsModelTest.test_update_review_progress_correct
```

## ğŸ“ Ajout de Nouveaux Tests

### Template de Test
```python
def test_new_feature(self):
    """Test de la nouvelle fonctionnalitÃ©"""
    # Arrange
    deck = FlashcardDeck.objects.create(...)
    
    # Act  
    result = deck.nouvelle_methode()
    
    # Assert
    self.assertEqual(result, expected_value)
```

### Bonnes Pratiques
1. **Noms descriptifs** : `test_update_progress_with_reset_enabled`
2. **Arrange-Act-Assert** : Structure claire
3. **Isolation** : Chaque test indÃ©pendant
4. **DonnÃ©es cohÃ©rentes** : Utiliser des valeurs rÃ©alistes
5. **Messages d'erreur clairs** : Faciliter le debugging

## ğŸ† Validation de l'ImplÃ©mentation

Ces tests valident que le systÃ¨me de paramÃ©trage d'apprentissage :

âœ… **Fonctionne correctement** selon les spÃ©cifications  
âœ… **GÃ¨re les cas d'erreur** de maniÃ¨re robuste  
âœ… **Maintient l'intÃ©gritÃ© des donnÃ©es** en toutes circonstances  
âœ… **Respecte les permissions** et la sÃ©curitÃ©  
âœ… **Performe bien** mÃªme avec beaucoup de donnÃ©es  
âœ… **S'intÃ¨gre parfaitement** avec le reste du systÃ¨me  

La suite de tests garantit la fiabilitÃ© et la qualitÃ© du systÃ¨me d'apprentissage personnalisable !